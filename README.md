# Market Data Hub

A production-ready data engineering project for Vietnamese stock market data processing and analysis.

## Overview

This project implements a complete data engineering workflow: extracting market data from VNStock API, orchestrating batch ingestion with Airflow, storing raw/processed data in MinIO (S3-compatible storage), loading structured data to PostgreSQL, and enabling analysis through Jupyter notebooks and Metabase dashboards.

**Key Technologies**: Python â€¢ Apache Airflow â€¢ Apache Spark â€¢ MinIO/S3 â€¢ PostgreSQL â€¢ Metabase â€¢ Docker

![Data Architecture](docs/image/data_architecture.png)

## What's Implemented

- âœ… **Batch Data Ingestion**: Python scripts for extracting stock and company data from VNStock API
- âœ… **Pipeline Orchestration**: Airflow DAGs for scheduling and monitoring data workflows
- âœ… **Data Lake Storage**: MinIO (S3-compatible) for bronze/silver layer data storage
- âœ… **Data Processing**: PySpark transformations for cleaning and structuring market data
- âœ… **Data Warehouse**: PostgreSQL for structured analytical data storage
- âœ… **Data Visualization**: Metabase dashboards for business intelligence and reporting
- âœ… **Exploratory Analysis**: Jupyter notebooks for ad-hoc data exploration and validation

## Quick Start

To run this project locally:

```bash
# Clone and navigate to project
git clone https://github.com/plat102/pj-market-data.git
cd pj-market-data

# Build and start services
make build
make up
```

### Accessing Services

Once services are running, you can access:

| Service | URL | Port | Credentials |
|---------|-----|------|-------------|
| **Airflow Webserver** | http://localhost:8081 | 8081 | user: `airflow`, pass: `airflow` |
| **MinIO Console** | http://localhost:9001 | 9001 | user: `minio`, pass: `minio123` |
| **Metabase** | http://localhost:3000 | 3000 | Setup on first access |
| **Spark Master** | http://localhost:8080 | 8080 | N/A |
| **PostgreSQL** | localhost:5433 | 5433 | user: `airflow`, pass: `airflow` |

![Docker Services](docs/image/docker_services.png)

### Running the Pipelines

**Data Ingestion Pipeline:**

![Airflow Ingestion DAG](docs/image/airflow_vnstock_ingest.png)

**Data Transformation Pipeline:**

![Airflow Transform DAG](docs/image/airflow_vnstock_transform.png)

**MinIO Data Lake:**

![MinIO Console](docs/image/minio.png)

For detailed setup instructions, environment configuration, and development workflow, see [`docs/developer_guide.md`](docs/developer_guide.md).

## Project Structure

```
finance_hub/
â”œâ”€â”€ airflow/           # Airflow DAGs and configuration
â”œâ”€â”€ src/pipeline/      # ETL modules (extract, transform, load)
â”œâ”€â”€ notebooks/         # Jupyter notebooks for analysis
â”œâ”€â”€ spark/             # Spark job configurations
â”œâ”€â”€ minio/             # Object storage data
â”œâ”€â”€ postgresql/        # Database initialization scripts
â””â”€â”€ docs/              # Detailed documentation
```

## Documentation

- ğŸ“– **[Developer Guide](docs/developer_guide.md)** - Setup, configuration, and development workflow
- ğŸ—ï¸ **[Architecture](docs/architecture.md)** - System design and component overview
- ğŸ—ºï¸ **[Roadmap](docs/roadmap.md)** - Project objectives and scope

## Key Learnings

- Designed and implemented an object-oriented ETL pipeline architecture
- Integrated Apache Spark and Airflow for scalable data processing
- Configured Docker-based multi-service orchestration for data engineering stack
- Applied medallion architecture pattern (bronze/silver layers) for data lake organization

## License & Contact

**Author**: Thu Phan  
**Repository**: [github.com/plat102/pj-market-data](https://github.com/plat102/pj-market-data)
